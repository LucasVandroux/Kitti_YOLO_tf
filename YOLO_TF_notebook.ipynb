{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO on TensorFlow\n",
    "\n",
    "This notebook aims to create a trainable and usable version of YOLO on TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** IMPORT ***\n",
    "import tensorflow as tf\n",
    "from tf_yolo_utils import *   # fcts. to create custom layers\n",
    "\n",
    "# Import kitti_utils from a different project\n",
    "import sys\n",
    "sys.path.insert(0, '/data2/lucas/Projects/Kitti2012')\n",
    "from kitti_utils import *    # fcts. to manage the kitti dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "|type            |  x_max     |  x_min     |  y_min     |  y_max     |\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "|Car             |  600.06    |  581.85    |  176.1     |  190.53    |\n",
      "----------------------------------------------------------------------\n",
      "|Car             |  399.96    |  292.06    |  183.14    |  243.71    |\n",
      "----------------------------------------------------------------------\n",
      "|DontCare        |  576.27    |  559.56    |  166.69    |  188.61    |\n",
      "----------------------------------------------------------------------\n",
      "|DontCare        |  603.36    |  574.15    |  162.52    |  177.15    |\n",
      "----------------------------------------------------------------------\n",
      "|DontCare        |  624.18    |  609.56    |  161.48    |  175.06    |\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_labels(import_labels(700, 'train'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The YOLO Architecture\n",
    "![The YOLO Architecture](doc_img/YOLO_architecture.png)\n",
    "\n",
    "The YOLO Detection network has 24 convolutional layers followed by 2 fully connected layers.\n",
    "\n",
    "The predictions are encoded as an S x S x (B * 5 + C) tensor where S x S is the size of the grid that divides the input images. B is the number of boxes in one cell grid, C the number of conditional class probabilites.\n",
    "\n",
    "N.B. __IoU (Intersection over Union)__ is an evaluation metric used to measure the accuracy of an object detector on a particular dataset.\n",
    "\n",
    "![Intersection over Union Illustration](doc_img/iou_equation+examples.png)\n",
    "_Source:[pyimagesearch.com](https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/)_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- HYPERPARAMETERS ---\n",
    "TRAIN_PERC = 60   # Percentage of the data to put in the training set\n",
    "DEV_PERC = 20     # Percentage of the data to put in the dev set\n",
    "TEST_PERC = 20    # Percentage of the data to put in the test set\n",
    "\n",
    "SEED = 42         # Seed used to randomize the dataset\n",
    "\n",
    "BATCH_SIZE = 50   # Size of a batch of data\n",
    "STEPS = 5000      # Number of step to train the CNN\n",
    "\n",
    "IM_SIZE = 448     # 448=7*64  (Original shape of the image=(375, 1242, 3))\n",
    "S = 7             # S x S grid the image is divided into\n",
    "B = 2             # B = number of boxes per cell grid\n",
    "C = 9             # C = number of labelled classes\n",
    "\n",
    "# --- IMPORT DATA ---\n",
    "ids_for_training = get_data_list('train')\n",
    "train_batches_ids, dev_batches_ids, test_batches_ids = prepare_dataset(ids_for_training, [TRAIN_PERC, DEV_PERC, TEST_PERC], BATCH_SIZE, SEED)\n",
    "\n",
    "# --- IMPORT BATCH ---\n",
    "# Function to import the images in the batches and to format the labels\n",
    "# - TODO -\n",
    "\n",
    "# --- DEFINE CNN ---\n",
    "x = tf.placeholder(tf.float32, shape=[None, IM_SIZE, IM_SIZE, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[None, S * S * (B * 5 + C)])\n",
    "\n",
    "# --- CONV. LAYER 1 ---\n",
    "# 7x7x64-s-2\n",
    "# Maxpool: 2x2-s-2\n",
    "\n",
    "conv1 = conv_layer(x, shape=[7, 7, 3, 64], strides=[1,2,2,1])\n",
    "conv1_pool = max_pool_2x2(conv1)\n",
    "\n",
    "# --- CONV. LAYER 2 ---\n",
    "# 3x3x192\n",
    "# Maxpool: 2x2-s-2\n",
    "\n",
    "conv2 = conv_layer(conv1_pool, shape=[3, 3, 64, 192], strides=[1,2,2,1])\n",
    "conv2_pool = max_pool_2x2(conv2)\n",
    "\n",
    "# --- CONV. LAYERS 3 ---\n",
    "# 1x1x128\n",
    "# 3x3x256\n",
    "# 1x1x256\n",
    "# 3x3x512\n",
    "# Maxpool: 2x2-s-2\n",
    "\n",
    "conv3_1 = conv_layer(conv2_pool, shape=[1, 1, 192, 128])\n",
    "conv3_2 = conv_layer(conv3_1, shape=[3, 3, 128, 256])\n",
    "conv3_3 = conv_layer(conv3_2, shape=[1, 1, 256, 256])\n",
    "conv3_4 = conv_layer(conv3_3, shape=[3, 3, 256, 512])\n",
    "conv3_pool = max_pool_2x2(conv3_4)\n",
    "\n",
    "# --- CONV. LAYERS 4 ---\n",
    "# 1x1x256  ____ x4\n",
    "# 3x3x512  _|\n",
    "# 1x1x512\n",
    "# 3x3x1024\n",
    "# Maxpool: 2x2-s-2\n",
    "\n",
    "conv4_1 = conv_layer(conv3_pool, shape=[1, 1, 512, 256])\n",
    "conv4_2 = conv_layer(conv4_1, shape=[3, 3, 256, 512])\n",
    "\n",
    "conv4_3 = conv_layer(conv4_2, shape=[1, 1, 512, 256])\n",
    "conv4_4 = conv_layer(conv4_3, shape=[3, 3, 256, 512])\n",
    "\n",
    "conv4_5 = conv_layer(conv4_4, shape=[1, 1, 512, 256])\n",
    "conv4_6 = conv_layer(conv4_5, shape=[3, 3, 256, 512])\n",
    "\n",
    "conv4_7 = conv_layer(conv4_6, shape=[1, 1, 512, 256])\n",
    "conv4_8 = conv_layer(conv4_7, shape=[3, 3, 256, 512])\n",
    "\n",
    "conv4_9 = conv_layer(conv4_8, shape=[1, 1, 512, 512])\n",
    "conv4_10 = conv_layer(conv4_9, shape=[3, 3, 512, 1024])\n",
    "\n",
    "conv4_pool = max_pool_2x2(conv4_10)\n",
    "\n",
    "# --- CONV. LAYERS 5 ---\n",
    "# 1x1x512   ____ x2\n",
    "# 3x3x1024  _|\n",
    "# 3x3x1024\n",
    "# 3x3x1024-s-2\n",
    "\n",
    "conv5_1 = conv_layer(conv4_pool, shape=[1, 1, 1024, 512])\n",
    "conv5_2 = conv_layer(conv5_1, shape=[3, 3, 512, 1024])\n",
    "\n",
    "conv5_3 = conv_layer(conv5_2, shape=[1, 1, 1024, 512])\n",
    "conv5_4 = conv_layer(conv5_3, shape=[3, 3, 512, 1024])\n",
    "\n",
    "conv5_5 = conv_layer(conv5_4, shape=[3, 3, 1024, 1024])\n",
    "\n",
    "conv5_6 = conv_layer(conv5_5, shape=[3, 3, 1024, 1024], strides=[1, 2, 2, 1])\n",
    "\n",
    "# --- CONV. LAYERS 6 ---\n",
    "# 3x3x1024\n",
    "# 3x3x1024\n",
    "\n",
    "conv6_1 = conv_layer(conv5_6, shape=[3, 3, 1024, 1024])\n",
    "conv6_2 = conv_layer(conv6_1, shape=[3, 3, 1024, 1024])\n",
    "\n",
    "# --- FULL LAYER 1 ---\n",
    "# 4096\n",
    "\n",
    "conv6_2_flatten = tf.reshape(conv6_2, [-1, 16 * 1024]) # Got it to 16*1024 to have only one l ouput per image\n",
    "\n",
    "full_1_ = full_layer(conv6_2_flatten, 4096)\n",
    "full_1 = tf.maximum(full_1_, 0.1 * full_1_)  # Leaky ReLU\n",
    "\n",
    "full_1_drop = tf.nn.dropout(full_1, keep_prob=0.5)\n",
    "\n",
    "# --- FULL LAYER 2 ---\n",
    "\n",
    "full_2 = full_layer(full_1_drop, S * S * (B * 5 + C))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 448, 448, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 931)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to get an image run through the CNN\n",
    "# import image\n",
    "im_1_ = import_im('111', 'train')\n",
    "im_1_ = misc.imresize(im_1_, (IM_SIZE, IM_SIZE, 3))\n",
    "im_1 = im_1_.reshape([-1, IM_SIZE, IM_SIZE, 3])\n",
    "\n",
    "im_2_ = import_im('222', 'train')\n",
    "im_2_ = misc.imresize(im_2_, (IM_SIZE, IM_SIZE, 3))\n",
    "im_2 = im_2_.reshape([-1, IM_SIZE, IM_SIZE, 3])\n",
    "\n",
    "ims = np.concatenate((im_1, im_2),axis=0)\n",
    "\n",
    "print(ims.shape)\n",
    "\n",
    "# initialize variables\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "result = sess.run(full_2, feed_dict = {x: ims})\n",
    "\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "931"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "![The YOLO Loss Function](doc_img/YOLO_loss_function.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
