{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** GLOBAL IMPORT ***\n",
    "import tensorflow as tf\n",
    "from tf_yolo_utils import *   # fcts. to create custom layers\n",
    "\n",
    "# Import kitti_utils from a different project\n",
    "import sys\n",
    "sys.path.insert(0, '/data2/lucas/Projects/Kitti2012')\n",
    "from kitti_utils import *    # fcts. to manage the kitti dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "This notebook is here to explore the effect of the different hyperparameters in the YOLO NN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Cells\n",
    "In this part, we explore the effect of the number of grid cells in the picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import list of ids\n",
    "ids_for_training = get_data_list('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage image where not all object are classify: 0.6015238604464644 with max per cell = 3.0\n"
     ]
    }
   ],
   "source": [
    "# get the minimum number to have one object per cell-grid\n",
    "\n",
    "S = 150     # Number of cell-grid size\n",
    "\n",
    "im_sample = import_im(1, 'train')\n",
    "im_height = im_sample.shape[0]\n",
    "im_width = im_sample.shape[1]\n",
    "\n",
    "general_max_obj_per_cell = 1\n",
    "num_im_with_overlap = 0\n",
    "list_num_obj_per_im = []\n",
    "\n",
    "for im_id in ids_for_training:\n",
    "# im_id = train_batches_ids[0][0]\n",
    "    grid_cells = np.zeros((S,S))\n",
    "    labels = import_labels(im_id, 'train')\n",
    "    list_num_obj_per_im.append(len(labels)) \n",
    "\n",
    "    for label in labels:\n",
    "        x_box_length = label['bbox']['x_max'] - label['bbox']['x_min']\n",
    "        x_center = (label['bbox']['x_min'] + (x_box_length/2)) / im_width\n",
    "\n",
    "        y_box_length = label['bbox']['y_max'] - label['bbox']['y_min']\n",
    "        y_center = (label['bbox']['y_min'] + (y_box_length/2)) / im_height\n",
    "\n",
    "        x_cell = math.floor(x_center * S)\n",
    "        y_cell = math.floor(y_center * S)\n",
    "\n",
    "        # print(label['type'] + ' with x_center: ' + str(x_center) + ' and y_center: ' + str(y_center) + ' is going to grid cell: (' + str(y_cell) + ', ' + str(x_cell) + ')')\n",
    "        grid_cells[y_cell][x_cell] += 1 \n",
    "    \n",
    "    max_obj_per_cell = np.amax(grid_cells)\n",
    "    \n",
    "    if max_obj_per_cell > 1:\n",
    "        num_im_with_overlap += 1\n",
    "    \n",
    "    if max_obj_per_cell > general_max_obj_per_cell:\n",
    "        general_max_obj_per_cell = max_obj_per_cell\n",
    "        \n",
    "perc_im_with_overlap = num_im_with_overlap / len(ids_for_training) * 100\n",
    "\n",
    "print('Percentage image where not all object are classify: ' + str(perc_im_with_overlap) + ' with max per cell = ' + str(general_max_obj_per_cell))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
